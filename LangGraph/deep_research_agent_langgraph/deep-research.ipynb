{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2866a7e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f859d4",
   "metadata": {},
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5084f52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clarify_with_user_instructions=\"\"\"\n",
    "These are the messages that have been exchanged so far from the user asking for the report:\n",
    "<Messages>\n",
    "{messages}\n",
    "</Messages>\n",
    "\n",
    "Today's date is {date}.\n",
    "\n",
    "Assess whether you need to ask a clarifying question, or if the user has already provided enough information for you to start research.\n",
    "IMPORTANT: If you can see in the messages history that you have already asked a clarifying question, you almost always do not need to ask another one. Only ask another question if ABSOLUTELY NECESSARY.\n",
    "\n",
    "If there are acronyms, abbreviations, or unknown terms, ask the user to clarify.\n",
    "If you need to ask a question, follow these guidelines:\n",
    "- Be concise while gathering all necessary information\n",
    "- Make sure to gather all the information needed to carry out the research task in a concise, well-structured manner.\n",
    "- Use bullet points or numbered lists if appropriate for clarity. Make sure that this uses markdown formatting and will be rendered correctly if the string output is passed to a markdown renderer.\n",
    "- Don't ask for unnecessary information, or information that the user has already provided. If you can see that the user has already provided the information, do not ask for it again.\n",
    "\n",
    "Respond in valid JSON format with these exact keys:\n",
    "\"need_clarification\": boolean,\n",
    "\"question\": \"<question to ask the user to clarify the report scope>\",\n",
    "\"verification\": \"<verification message that we will start research>\"\n",
    "\n",
    "If you need to ask a clarifying question, return:\n",
    "\"need_clarification\": true,\n",
    "\"question\": \"<your clarifying question>\",\n",
    "\"verification\": \"\"\n",
    "\n",
    "If you do not need to ask a clarifying question, return:\n",
    "\"need_clarification\": false,\n",
    "\"question\": \"\",\n",
    "\"verification\": \"<acknowledgement message that you will now start research based on the provided information>\"\n",
    "\n",
    "For the verification message when no clarification is needed:\n",
    "- Acknowledge that you have sufficient information to proceed\n",
    "- Briefly summarize the key aspects of what you understand from their request\n",
    "- Confirm that you will now begin the research process\n",
    "- Keep the message concise and professional\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dce8f7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../deep_research_agent_langgraph/src/state_scope.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../deep_research_agent_langgraph/src/state_scope.py\n",
    "\n",
    "\"\"\"State Definitions and Pydantic Schemas for Research Scoping.\n",
    "\n",
    "This defines the state objects and structured schemas used for\n",
    "the research agent scoping workflow, including researcher state management and output schemas.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "import operator\n",
    "from typing_extensions import Optional, Annotated, List, Sequence\n",
    "\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.graph import MessagesState\n",
    "from langgraph.graph.message import add_messages\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# state definitions\n",
    "\n",
    "class AgentInputState (MessagesState):\n",
    "\n",
    "    ''' input state for the full agent, contains message only '''\n",
    "    pass\n",
    "\n",
    "class AgentState (MessagesState):\n",
    "\n",
    "    '''\n",
    "    Main state for the full multi-agent research system.\n",
    "        \n",
    "    Extends MessagesState with additional fields for research coordination. '''\n",
    "\n",
    "    # research brief generated from user conversation history\n",
    "    research_breif: Optional[str]\n",
    "        \n",
    "    # messages exchanged with the supervisor agent for coordination\n",
    "    supervisor_messages: Annotated[Sequence[BaseMessage], add_messages ]\n",
    "\n",
    "    # Raw unprocessed research notes collected during the research phase\n",
    "    raw_notes: Annotated[List[str], operator.add] = []\n",
    "\n",
    "    # Processed and structured notes ready for report generation\n",
    "    notes: Annotated[list[str], operator.add] = []\n",
    "\n",
    "    # Final formatted research report\n",
    "    final_report: str\n",
    "\n",
    "\n",
    "# structured output schemas\n",
    "\n",
    "class ClarifyWithUser (BaseModel):\n",
    "\n",
    "    '''Schema for clarifying questions to the user.'''\n",
    "\n",
    "    need_clarification: bool = Field(\n",
    "        ..., description=\"Whether a clarifying question is needed.\"\n",
    "    )\n",
    "    question: str = Field(\n",
    "        \"\", description=\"The clarifying question to ask the user, if needed.\"\n",
    "    )\n",
    "    verification: str = Field(\n",
    "        \"\", description=\"Verification message if no clarification is needed.\"\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0fe26af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../deep_research_agent_langgraph/src/research_agent_scope.py\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%writefile ../deep_research_agent_langgraph/src/research_agent_scope.py\n",
    "\n",
    "\n",
    "''' user clarification and research breif generation'''\n",
    "\n",
    "from datetime import datetime\n",
    "from langchain.chat_models import init_chat_model\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "from  langchain_core.messages import HumanMessage, AIMessage, get_buffer_string\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.types import Command\n",
    "\n",
    "from deep_research_agent_langgraph.src.prompts import clarify_with_user_instructions, transform_messages_into_research_topic_prompt\n",
    "from deep_research_agent_langgraph.src.state_scope import AgentState, ClarifyWithUser, ResearchQuestion, AgentInputState\n",
    "from typing_extensions import Literal\n",
    "\n",
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "if google_api_key:\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = google_api_key\n",
    "else:\n",
    "    \n",
    "    print(\"Warning: GOOGLE_API_KEY is not set. Continuing without setting the environment variable.\")\n",
    "\n",
    "# utility func\n",
    "def get_today_str() -> str:\n",
    "    \"\"\"Get current date in a human-readable format.\"\"\"\n",
    "    \n",
    "    now = datetime.now()\n",
    "    return now.strftime(\"%a %b {}, %Y\").format(now.day)\n",
    "\n",
    "# config\n",
    "model = init_chat_model ( \"gemini-2.5-flash\", model_provider=\"google_genai\", temperature=0)\n",
    "\n",
    "def clarify_with_user (state: AgentState) -> Command[Literal[\"write_research_brief\", \"__end__\"]]:\n",
    "\n",
    "    ''' Clarify the research topic with the user if needed, else generate a research brief.'''\n",
    "\n",
    "    # structured output model\n",
    "\n",
    "    structured_output_model = model.with_structured_output(ClarifyWithUser)\n",
    "\n",
    "    # invoke model with clarification instructions\n",
    "\n",
    "    response = structured_output_model.invoke ([\n",
    "        \n",
    "        HumanMessage(content=clarify_with_user_instructions.format(\n",
    "            \n",
    "            messages = get_buffer_string(messages = state[\"messages\"]),\n",
    "            date = get_today_str()\n",
    "            ) ) ])\n",
    "\n",
    "    \n",
    "    if response.need_clarification:\n",
    "\n",
    "        return Command(\n",
    "            goto=START,\n",
    "            update = { \"messages\": [AIMessage (content=response.question)] }\n",
    "        )\n",
    "\n",
    "    else: \n",
    "        return Command(\n",
    "            goto=\"write_research_brief\",\n",
    "            update = { \"messages\": [AIMessage (content=response.verification)] }\n",
    "        )\n",
    "\n",
    "\n",
    "def write_research_brief(state: AgentState):\n",
    "    \"\"\"\n",
    "    Transform the conversation history into a comprehensive research brief.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    structured_output_model = model.with_structured_output(ResearchQuestion)\n",
    "    \n",
    "    #  research brief from conversation history\n",
    "    response = structured_output_model.invoke([\n",
    "        HumanMessage(content=transform_messages_into_research_topic_prompt.format(\n",
    "            messages=get_buffer_string(state.get(\"messages\", [])),\n",
    "            date=get_today_str()\n",
    "        ))\n",
    "    ])\n",
    "    \n",
    "    # pass to supervisor\n",
    "    \n",
    "    return {\n",
    "        \"research_brief\": response.research_brief,\n",
    "        \"supervisor_messages\": [HumanMessage(content=f\"{response.research_brief}.\")]\n",
    "    }\n",
    "\n",
    "# graph construction\n",
    "\n",
    "deep_researcher_builder = StateGraph (AgentState, input_schema = AgentInputState)\n",
    "\n",
    "#nodes \n",
    "\n",
    "deep_researcher_builder.add_node (\"clarify_with_user\", clarify_with_user )\n",
    "deep_researcher_builder.add_node (\"write_research_brief\", write_research_brief )\n",
    "\n",
    "#edges\n",
    "\n",
    "deep_researcher_builder.add_edge (START, \"clarify_with_user\")\n",
    "deep_researcher_builder.add_edge  (\"write_research_brief\", END)\n",
    "\n",
    "# compile\n",
    "scope_research = deep_researcher_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "20d5f2d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'deep_researcher_builder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlanggraph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcheckpoint\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmemory\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InMemorySaver\n\u001b[0;32m      3\u001b[0m checkpointer \u001b[38;5;241m=\u001b[39m InMemorySaver()\n\u001b[1;32m----> 4\u001b[0m scope \u001b[38;5;241m=\u001b[39m \u001b[43mdeep_researcher_builder\u001b[49m\u001b[38;5;241m.\u001b[39mcompile(checkpointer\u001b[38;5;241m=\u001b[39mcheckpointer)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Run the workflow\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m format_messages\n",
      "\u001b[1;31mNameError\u001b[0m: name 'deep_researcher_builder' is not defined"
     ]
    }
   ],
   "source": [
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "checkpointer = InMemorySaver()\n",
    "scope = deep_researcher_builder.compile(checkpointer=checkpointer)\n",
    "\n",
    "# Run the workflow\n",
    "from utils import format_messages\n",
    "from langchain_core.messages import HumanMessage\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "result = scope.invoke({\"messages\": [HumanMessage(content=\"I want to research the best coffee shops in San Jose.\")]}, config=thread)\n",
    "format_messages(result['messages'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18deafdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
